{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to build a baseline model to perform binary class sentiment analysis. Model uses pretrained glove twitter embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                              1.4.0              \n",
      "torchvision                        0.5.0              \n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install --timeout 60 pytorch #-r ../utils/requirements3.txt\n",
    "!pip3 list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.3.2)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.8.0-cp36-cp36m-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 15.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (4.42.1)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (45.2.0.post20200210)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (1.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.8.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting en_core_web_sm==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.42.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.9.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (45.2.0.post20200210)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.10)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.2.0)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047105 sha256=5c8248897cc9f5faa259bffd7c068576b67bcd4d1c87a711dd960ace624d6bbd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-pjq9bykc/wheels/10/6f/a6/ddd8204ceecdedddea923f8514e13afb0c1f0f556d2c9c3da0\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.3.1\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/en_core_web_sm\n",
      "-->\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!pip3 install spacy torchtext #==0.3.1  #umap umap-learn holoviews dash dash-ui\n",
    "!python3 -m spacy download en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Binary classifier\n",
    "Reworked from examples here to play with torchtext\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from torchtext import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = '../data/'\n",
    "model_dir = '../model/'\n",
    "\n",
    "sentiments = pd.read_csv(data_dir+'/Tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and processing data. Remove null text and only use tweet, airline, label (positive and negative only) and tweet id to build a binary classifier. Split dataset into train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = sentiments[sentiments['text'].notnull() &\n",
    "                      sentiments['airline'].notnull() &\n",
    "                      sentiments['airline_sentiment'].notnull() &\n",
    "                      sentiments['tweet_id'].notnull()]\n",
    "# use only tweet(text), airline, label (airline_sentiment) and tweet id\n",
    "final_df = clean_df.filter(['tweet_id', 'text', 'airline',\n",
    "                           'airline_sentiment'], axis=1)\n",
    "# use only positive and negative sentiment\n",
    "row_vals = ['positive', 'negative']\n",
    "final_df = final_df.loc[final_df['airline_sentiment'].isin(row_vals)]\n",
    "# split into train, test, val (.7, .15, .15)\n",
    "train_df, testval_df = train_test_split(final_df, test_size=0.3)\n",
    "test_df, val_df = train_test_split(testval_df, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataframes back to csv so we can load into Torchtext easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  self.postprocessing = postprocessing\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  self.postprocessing = postprocessing\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n"
     ]
    }
   ],
   "source": [
    "# convert df back to csv, with column names\n",
    "train_df.to_csv(data_dir+'/train.csv', index=False)\n",
    "test_df.to_csv(data_dir+'/test.csv', index=False)\n",
    "val_df.to_csv(data_dir+'/val.csv', index=False)\n",
    "\n",
    "# load into torchtext\n",
    "ID = data.Field()\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "SENTIMENT = data.LabelField(dtype=torch.float)\n",
    "AIRLINE = data.Field()\n",
    "\n",
    "# access using batch.id, batch.text etc\n",
    "fields = [('id', ID), ('text', TEXT), ('airline', AIRLINE), ('label', SENTIMENT)]\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(path=data_dir,\n",
    "                                                               train='train.csv',\n",
    "                                                               validation='val.csv',\n",
    "                                                               test='test.csv',\n",
    "                                                               format='csv',\n",
    "                                                               fields=fields,\n",
    "                                                               skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.twitter.27B.zip: 1.52GB [11:48, 2.15MB/s]                               \n",
      "100%|█████████▉| 1193366/1193514 [00:36<00:00, 31070.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 8279), ('to', 4862), ('I', 3583), ('the', 3472), ('!', 3166), ('a', 2508), (',', 2364), ('for', 2357), ('you', 2254), ('?', 2237), ('and', 2213), ('@united', 2166), ('on', 2116), ('#', 2092), ('flight', 1790), ('my', 1780), ('@USAirways', 1759), ('@AmericanAir', 1682), ('is', 1614), ('in', 1462)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1193366/1193514 [00:50<00:00, 31070.66it/s]"
     ]
    }
   ],
   "source": [
    "# build iterators\n",
    "MAX_VOCAB_SIZE = 10_000\n",
    "\n",
    "ID.build_vocab(train_data)\n",
    "# TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
    "TEXT.build_vocab(train_data,\n",
    "                 max_size=MAX_VOCAB_SIZE,\n",
    "                 vectors=\"glove.twitter.27B.25d\",\n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "SENTIMENT.build_vocab(train_data)\n",
    "AIRLINE.build_vocab(train_data)\n",
    "\n",
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this - need for model prediction\n",
    "outfile = open(model_dir+'vocab_index.pkl', 'wb')\n",
    "pickle.dump(TEXT.vocab.stoi, outfile, -1)\n",
    "outfile.close()\n",
    "#cdsw.track_file(model_dir+'vocab_index.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make data iterators so we can load batches properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  repeat=False, shuffle=None, sort=None,\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    sort_key=lambda x: x.text,  # sort by text\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple RNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "       \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "       \n",
    "    def forward(self, text):\n",
    "\n",
    "        # text = [sent len, batch size]\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded = [sent len, batch size, emb dim]\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        # output = [sent len, batch size, hid dim]\n",
    "        # hidden = [1, batch size, hid dim]\n",
    "        assert torch.equal(output[-1, :, :], hidden.squeeze(0))\n",
    "\n",
    "        return self.fc(hidden.squeeze(0)), hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set model parameters and instantiate the RNN. The input dimension is the length of the vocabulary (10,000), the embedding dimension is the length of the glove pretrained vector (25). The hidden dimension is the size of the hidden layer, the output dimension is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "# EMBEDDING_DIM = 100\n",
    "EMBEDDING_DIM = 25\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy pretrained vector into the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10002, 25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1143,  0.4464,  0.6869,  ..., -1.3202,  0.0078,  0.9977],\n",
       "        [-0.2811,  0.9827,  0.1755,  ...,  0.6664, -2.5255,  0.7648],\n",
       "        [ 0.6959, -1.1469, -0.4180,  ..., -0.6788,  0.7061,  0.4083],\n",
       "        ...,\n",
       "        [ 0.1354, -0.0800, -1.7132,  ...,  0.8441,  0.3477, -1.1076],\n",
       "        [-0.9546,  0.2650, -0.6307,  ..., -0.1836,  0.4218, -1.1000],\n",
       "        [-1.2681, -1.4116, -0.0722,  ...,  0.3411, -0.9011, -1.3320]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and evaluation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #predictions = model(batch.text).squeeze(1)\n",
    "        predictions, _ = model(batch.text)\n",
    "        predictions = predictions.squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "   \n",
    "    model.eval()\n",
    "   \n",
    "    with torch.no_grad():\n",
    "   \n",
    "        for batch in iterator:\n",
    "\n",
    "            #predictions = model(batch.text).squeeze(1)\n",
    "            predictions, _ = model(batch.text)\n",
    "            predictions = predictions.squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set optimizer and training criterion for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  self.batch_size = len(data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.507 | Train Acc: 78.93%\n",
      "\t Val. Loss: 0.486 |  Val. Acc: 81.02%\n",
      "Epoch: 02 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.515 | Train Acc: 78.71%\n",
      "\t Val. Loss: 0.507 |  Val. Acc: 81.02%\n",
      "Epoch: 03 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.516 | Train Acc: 79.12%\n",
      "\t Val. Loss: 0.513 |  Val. Acc: 81.02%\n",
      "Epoch: 04 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.516 | Train Acc: 79.06%\n",
      "\t Val. Loss: 0.487 |  Val. Acc: 81.02%\n",
      "Epoch: 05 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.517 | Train Acc: 79.04%\n",
      "\t Val. Loss: 0.487 |  Val. Acc: 81.02%\n",
      "Test Loss: 0.506 | Test Acc: 79.68%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_dir+'/rnn_binary_pretrain_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    \n",
    "model.load_state_dict(torch.load(model_dir+'/rnn_binary_pretrain_model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return prediction, embedding, tweet and airline for front end using test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_from_dataset(model, tokenized):\n",
    "    model.eval()\n",
    "    # tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    # print(tensor)\n",
    "    sentiment, hidden = model(tensor)\n",
    "    prediction = torch.sigmoid(sentiment)\n",
    "    return prediction.item(), hidden\n",
    "\n",
    "# save for front-end application\n",
    "prediction_list = []\n",
    "embedding_list = []\n",
    "airline_list = []\n",
    "tweet_list = []\n",
    "for example in test_data:\n",
    "    text = example.text  # this is tokenized\n",
    "    airline = example.airline\n",
    "    prediction, embedding = predict_sentiment_from_dataset(model, text)\n",
    "    tweet_list.append(text)\n",
    "    prediction_list.append(prediction)\n",
    "    embedding_list.append(embedding.data.numpy().squeeze(1))\n",
    "    airline_list.append(airline)\n",
    "\n",
    "output_dict = {\"prediction\": prediction_list,\n",
    "               \"embedding\": embedding_list,\n",
    "               \"tweet\": tweet_list,\n",
    "               \"airline\": airline_list}\n",
    "outfile = open(data_dir+'frontend_data', 'wb')\n",
    "pickle.dump(output_dict, outfile, -1)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
